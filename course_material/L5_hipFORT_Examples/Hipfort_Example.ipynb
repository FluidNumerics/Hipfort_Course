{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e72da1e7-84c0-4e8a-81af-6fc0b2351727",
   "metadata": {},
   "source": [
    "# A complete Hipfort application\n",
    "\n",
    "In the <a href=\"../L1_Fortran_Refresher/Fortran.html\">Fortran Refresher lesson</a> <a href=\"../L1_Fortran_Refresher/Fortran.ipynb\">(ipynb)</a> we covered the essentials of the Fortran language and how to use `subroutines`, `functions`, `pointers`, `modules` as well as how to call C code from Fortran. If these topics are unfamiliar to you, then it might be useful to review the material in that section first!\n",
    "\n",
    "From the <a href=\"../L2_GPU_Computing_Fundamentals/Fundamentals.html\">GPU Computing Fundamentals </a><a href=\"../L2_GPU_Computing_Fundamentals/Fundamentals.ipynb\">(ipynb)</a> section, every accelerated application has the same basic design:\n",
    "\n",
    "1. At program launch, compute devices are discovered and initialized.\n",
    "2. Memory spaces are allocated on the compute device.\n",
    "3. Kernels are prepared.\n",
    "4. Memory is copied from the host to the compute device.\n",
    "5. Kernels are run to perform whatever compute operation is required.\n",
    "6. The output from kernel runs is copied back from the compute device to the host. IO may then occur before the next iteration.\n",
    "  \n",
    "**Steps 4-6** are repeated as many times as neccessary until the program is done, then at completion of the program\n",
    "\n",
    "7. Deallocate memory, \n",
    "8. Release resources and exit.\n",
    "\n",
    "## Tensor addition math\n",
    "\n",
    "In this section we are going to walk through each of these steps as part of a complete example with hipFORT, using 2D tensor addition as the basic algorithm. For 2D tensors **A**, **B**, and **C**, each of size (M,N), the following relationship holds true at each index (i,j) in the tensors.\n",
    "\n",
    "$$\n",
    "A(i,j)+B(i,j)=C(i,j)\n",
    "$$\n",
    "\n",
    "In the prior **Fortran Refresher** section we used CPU code in Fortran and C to compute the answer $C(i)$ for 1D tensor addition. In this example we are going to use a HIP Kernel on the GPU to compute the answer $C(i,j)$ at every location in **C**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff9d013-3e39-4f66-a1be-2e2409f460d1",
   "metadata": {},
   "source": [
    "## Example applications\n",
    "\n",
    "In HIP we need a way to get a handle on the memory allocations that are on the compute device. HipFORT can use either a `C` pointer of Fortran type `c_ptr` or a Fortran pointer as a handle to the memory allocations on the GPU. The methods of working with each type are subtly different though. In the applications \n",
    "\n",
    "* [tensoradd_hip_cptr.f90](tensoradd_hip_cptr.f90)\n",
    "* [tensoradd_hip_fptr.f90](tensoradd_hip_fptr.f90)\n",
    "\n",
    "we use C pointers and Fortran pointers to perform 2D tensor addition. It will be helpful to have **both files open** at the same time for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dd78fc-3fc9-43e3-8fda-ba5cd6f5d2cf",
   "metadata": {},
   "source": [
    "## Use the hipFORT API\n",
    "\n",
    "Access to all hipFORT functions is via the `hipfort` and `hipfort_check` modules. We bring those modules in along with others at the beginning of the program.\n",
    "\n",
    "```Fortran\n",
    "    ! HIP modules\n",
    "    use hipfort\n",
    "    use hipfort_check\n",
    "```\n",
    "\n",
    "## Check HIP API calls\n",
    "\n",
    "HipFORT functions usually have a **return type** that we can check to make sure everything worked ok. If these checks are **not performed** some functions will return even though there has been a **silent failure**.  It is therefore **best practice** to **always** the check the return type from hipFORT calls. The `hipfort_check` module defines a subroutine called `hipcheck` that we can use to wrap around a hipFORT API call. It then checks the return type and exits the program if there has been an error. For example we wrap `hipcheck` around a `hipmalloc` call as follows:\n",
    "\n",
    "```\n",
    "call hipcheck(hipmalloc(A_d, M, N))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cdb596-6fdc-4d8d-adf0-aedc19fe6a2e",
   "metadata": {},
   "source": [
    "## Code validation\n",
    "\n",
    "It is important to make sure that the output of the compuation is accurate for every element in the output. Wrong answers can be computed very quickly but they are of no value! In the **src** folder is a file called <a href=\"../src/math_utils.f90\">math_utils.f90</a>. It contains a module called `math_utils` that is intended to contain functions for working with tensors on the CPU. Within the module is a function called `check_tensor_addition_2D` that iterates over every point in a passed-in tensor $C(i,j)$ and checks to see each point is within an error margin of $A(i,j)+B(i,j)$. The function has the following signature, where **A**, **B**, and **C** are arrays on the host:\n",
    "\n",
    "```Fortran\n",
    "function check_tensor_addition_2D(A, B, C, eps_mult) result(success)\n",
    "            !! Function to check the outcome of tensor addition\n",
    "            !! only check the host arrays\n",
    "\n",
    "            real(kind=c_float), dimension(:,:), intent(in), pointer :: A, B, C\n",
    "        \n",
    "            real, intent(in) :: eps_mult\n",
    "                !! Epsilon multiplier, how many floating point spacings\n",
    "                !! can the computed answer be from our benchmark answer\n",
    "```\n",
    "\n",
    "Within the tensoradd programs we import `check_tensor_addition_2D` and rename it as the function `check` \n",
    "\n",
    "```Fortran\n",
    "! Maths check\n",
    "    use math_utils, only : check => check_tensor_addition_2D\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a29da-1a64-4328-b92b-264cbfa91512",
   "metadata": {},
   "source": [
    "## Fortran interface to kernel launch function\n",
    "\n",
    "HipFORT doesn't yet have a way to launch kernels, however passing C-pointers from Fortran to C/C++ functions is straightforward, and from C/C++ code we can launch kernels. In the file [kernel_code.cpp](kernel_code.cpp) is a C  function called `launch_kernel_hip` that does the job of launching kernels. It has the following signature:\n",
    "\n",
    "```Fortran\n",
    "    void launch_kernel_hip(\n",
    "            float_type* A, \n",
    "            float_type* B,\n",
    "            float_type* C,\n",
    "            int M,\n",
    "            int N) {\n",
    "```\n",
    "\n",
    "In order to call this function from Fortran we define an `interface` to the function within the programs of [tensoradd_hip_cptr.f90](tensoradd_hip_cptr.f90) and [tensoradd_hip_fptr.f90](tensoradd_hip_fptr.f90) as follows:\n",
    "\n",
    "```Fortran\n",
    "    interface\n",
    "        ! A C function with void return type\n",
    "        ! is regarded as a subroutine in Fortran \n",
    "        subroutine launch_kernel_hip(A, B, C, M, N) bind(C)\n",
    "            use iso_c_binding\n",
    "            ! Fortran passes arguments by reference as the default\n",
    "            ! Arguments must have the \"value\" option present to pass by value\n",
    "            ! Otherwise launch_kernel will receive pointers of type void**\n",
    "            ! instead of void*\n",
    "            type(c_ptr), intent(in), value :: A, B, C\n",
    "            integer(c_int), intent(in), value :: M, N\n",
    "        end subroutine\n",
    "        \n",
    "    end interface\n",
    "\n",
    "```\n",
    "\n",
    "Note the presence of the `value` option for the input arguments. This is so we pass arguments by `value` instead of by **reference** (the default). If we didn't have the value keyword the C function would receive a reference (or pointer to the variables) instead of a copy of the variables. In the case of `launch_kernel_hip` without the `value` keyword in the interface then A would be of type `void**` instead of `void*`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c9ae1b-6ec0-426b-9db6-10fba3b83292",
   "metadata": {},
   "source": [
    "## Strategies for maintaining consistency in precision\n",
    "\n",
    "In the file [kernel_code.cpp](kernel_code.cpp) you might have noticed the use of `float_type`. This is a typedef that determines the data type of elements within the tensors. It is set to `double` in <a href=\"../src/kinds.h\">../src/kinds.h</a> if the macro `USE_C_DOUBLE` is defined. Otherwise it is type-defined as `float`.\n",
    "\n",
    "```C++\n",
    "#ifdef USE_C_DOUBLE\n",
    "    typedef float float_type;\n",
    "#else\n",
    "    typedef double float_type;\n",
    "#endif\n",
    "```\n",
    "\n",
    "We include `kinds.h` from [kernel_code.cpp](kernel_code.cpp) to make this type available. \n",
    "\n",
    "```C++\n",
    "// Include this to make float_type available\n",
    "#include \"kinds.h\"\n",
    "```\n",
    "\n",
    "Element types must **be consistent** when arrays are accessed from both Fortran and C/C++. In Fortran the `iso_c_binding` module provides  `c_float` and `c_double` kinds that are equivalent to `float` and `double` in C/C++.  The `iso_fortran_env` module has `real32` and `real64` kinds for creating reals of 32-bit and 64-bit floats. These correspond to the C types `float` and `double` for IEEE-754 compliant floating point implementations. \n",
    "\n",
    "In <a href=\"../src/kinds.f90\">../src/kinds.f90</a> we employ a similar method to declare `float_type` as a kind within the `kinds` module. We use associate `float_type` with `c_double` if `USE_C_DOUBLE` is defined, and with `c_float` otherwise.\n",
    "\n",
    "```Fortran\n",
    "#ifdef USE_C_DOUBLE\n",
    "   ! Set float_type as c_double from iso_c_binding module\n",
    "   use, intrinsic :: iso_c_binding, only : float_type => c_double\n",
    "#else\n",
    "   ! Set float_type as c_float from iso_c_binding module\n",
    "   use, intrinsic :: iso_c_binding, only : float_type => c_float\n",
    "#endif\n",
    "```\n",
    "\n",
    "In [tensoradd_hip_cptr.f90](tensoradd_hip_cptr.f90) we can `use` the `kinds` module and create real variables of kind `float_type`.\n",
    "\n",
    "```Fortran\n",
    "! Use the kinds module to make available the float_type kind\n",
    "    use kinds\n",
    "\n",
    "    ...\n",
    "\n",
    "    ! Fortran pointers to memory allocations on the host\n",
    "    real(float_type), dimension(:,:), pointer :: A_h, B_h, C_h \n",
    "```\n",
    "\n",
    "Now we can be sure that `float_type` corresponds to a floating point number of a consistent precision, even when compiler flags set the default precision of `reals` to something else. One less source of bugs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594eb06-9d38-4651-a518-ba28488f379f",
   "metadata": {},
   "source": [
    "## Select and manage a HIP device\n",
    "\n",
    "Every HIP device that a program has access to is associated with a `primary context`. The primary context is a resource manager for keeping track of all the resources allocated on that device for the program. Host threads share access to primary contexts in a way that is (or at least is intended to be!) thread safe. Every host thread in an program is **free to choose** which device to use. Usually the HIP runtime is initialised, a primary context is created and a host thread is **connected** to the first available device (device 0) whenever that host thread makes its first call to a HIP function. For environments and programs where there are multiple devices and host threads, it is **good practice** to explicity initialize the HIP API and be specific about which device you would like the host thread to connect to. In the file <a href=\"../src/hip_utils.f90\">../src/hip_utils.f90</a> are two subroutines `init_device` and `reset_device` that provide a way to choose a GPU device and reset (release all resources) in the selected device's primary context. The first statement after variable declarations in  [tensoradd_hip_cptr.f90](tensoradd_hip_cptr.f90) and [tensoradd_hip_fptr.f90](tensoradd_hip_fptr.f90) is to initialize HIP and choose the GPU.\n",
    "\n",
    "```Fortran\n",
    "    ! Find and set the GPU device. Use device 0 by default\n",
    "    call init_device(0)   \n",
    "```\n",
    "\n",
    "The argument to `init_device` is the desired index of the device that we'd like to use. Device indices start at 0 and in this instance we select the first available gpu (with id 0). Inside the subroutine `init_device` we initialize the HIP API using a call to `hipinit`.\n",
    "\n",
    "```Fortran\n",
    "call hipcheck(hipinit(0))\n",
    "```\n",
    "\n",
    "The call to `hipinit` only needs to be done once, so we have a variable `acquired` within the module to make sure of this. \n",
    "\n",
    "Within `init_device`, we then call `hipgetdevicecount` to poll the number of valid devices. If the desired device index (the input argument to `init_device`) falls within the range of valid device then we call `hipsetdevice` to set the HIP device according to the desired device index. Any subsequent HIP calls from a host thread will then use the selected GPU.\n",
    "\n",
    "```Fortran\n",
    " ! Get the number of compute devices\n",
    "        call hipcheck(hipgetdevicecount(ndevices))\n",
    "            \n",
    "        if ((dev_id .ge. 0) .and. (dev_id .lt. ndevices)) then\n",
    "            ! Choose a compute device\n",
    "            call hipcheck(hipsetdevice(dev_id))\n",
    "        else\n",
    "            write(error_unit,*) 'Error, dev_id was not inside the range of available devices.'\n",
    "            stop 1\n",
    "        end if\n",
    "```\n",
    "\n",
    "The function `reset_device` in [hip_utils.f90](hip_utils.f90) calls `hipdevicesynchronize` to make sure the selected GPU device is finished with all pending activity, then it calls `hipdevicereset` to release all resources in the primary context. \n",
    "\n",
    "```Fortran\n",
    "        ! Release all resources on the gpu\n",
    "        if (acquired) then\n",
    "            ! Make sure the GPU is finished\n",
    "            ! with all pending activity\n",
    "            call hipcheck(hipdevicesynchronize())\n",
    "\n",
    "            ! Now free all resources on the primary context\n",
    "            ! of the selected GPU\n",
    "            call hipcheck(hipdevicereset())\n",
    "        end if\n",
    "```\n",
    "\n",
    "It is **best practice** to reset the compute device at the end of the computation, but make sure that no other threads are using resources on that GPU when you do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f2d9f-7768-40ed-a613-0f7397e7d99d",
   "metadata": {},
   "source": [
    "## Memory on the device\n",
    "\n",
    "### Standard data types on the host\n",
    "\n",
    "Next, we allocate memory for the tensors on both the host and the compute device. Fortran has the ability to change, with a compiler flag, how many bytes are used for `real` and `integer` types. When we work with Fortan and C/C++ precision needs to be consistent. We use the `float_type` discussed earlier to declare pointers `A_h`, `B_h`, and `C_h` for arrays on the host.\n",
    "\n",
    "```Fortran\n",
    "real(float_type), dimension(:,:), pointer :: A_h, B_h, C_h\n",
    "\n",
    "! Allocate memory on host \n",
    "allocate(A_h(M,N), B_h(M, N), C_h(M,N))\n",
    "```\n",
    "\n",
    "### Variable naming convention\n",
    "\n",
    "Notice the `_h` suffix on variable names. In this module we choose to put a `_h` suffix on memory allocations that reside on the host and a `_d` suffix for memory allocations that reside on the compute device. It is a variable naming convention that makes it easier to see what memory is allocated where."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe3074-8276-4110-b1b9-76d98893e95b",
   "metadata": {},
   "source": [
    "### C pointers and Fortran pointers\n",
    "\n",
    "Both C pointers of type `c_ptr` and Fortran pointers can be used as handles to memory allocations on the compute device. C pointers are flexible but not very safe. Fortran pointers are also not very safe but additionally  retain information on the shape, data type, and size of the allocation.\n",
    "\n",
    "In [tensoradd_hip_cptr.f90](tensoradd_hip_cptr.f90) we use C pointers for memory allocations to tensors **A**, **B**, and **C** on the compute device\n",
    "\n",
    "```Fortran\n",
    "    ! C Pointers to memory allocations on the device\n",
    "    type(c_ptr) :: A_d, B_d, C_d\n",
    "```\n",
    "\n",
    "and in [tensoradd_hip_fptr.f90](tensoradd_hip_fptr.f90) we use Fortran pointers.\n",
    "\n",
    "```Fortran\n",
    "    ! Fortran pointers to memory allocations on the device\n",
    "    real(float_type), dimension(:,:), pointer :: A_d, B_d, C_d\n",
    "```\n",
    "\n",
    "### Allocate device memory\n",
    "\n",
    "The `hipMalloc` function allocates memory in the **global** memory space on the compute device. This memory is the largest (and slowest) memory on the compute device. Memory allocated with `hipMalloc` is accessible from every kernel that runs on the compute device but not from the host. Either C pointers or Fortran pointers may be used with `hipMalloc`.\n",
    "\n",
    "When using hipmalloc with **C pointers** we need to specify how many **bytes** to reserve. The `sizeof` function returns the number of bytes allocated for a Fortran pointer. In [tensoradd_hip_cptr.f90](tensoradd_hip_cptr.f90) we use the bytes allocated for host arrays as an input argument when allocating **A_d**, **B_d**, and **C_d**. \n",
    "\n",
    "```Fortran\n",
    "    ! Allocate tensors on the device\n",
    "    call hipcheck(hipMalloc(A_d, int(sizeof(A_h), c_size_t)))\n",
    "    call hipcheck(hipMalloc(B_d, int(sizeof(B_h), c_size_t)))\n",
    "    call hipcheck(hipMalloc(C_d, int(sizeof(C_h), c_size_t)))\n",
    "```\n",
    "\n",
    "The `sizeof` intrinsic function produces a different data type across different compilers, therefore we the `int` function to make sure the number of bytes returned is an integer of kind `c_size_t`.\n",
    "\n",
    "Memory allocations that use Fortran pointers need **elements** (not bytes) as the input argument for allocation with `hipMalloc`. In [tensoradd_hip_fptr.f90](tensoradd_hip_fptr.f90) we specify the size of the arrays to allocate in elements along each dimension.\n",
    "\n",
    "```Fortran\n",
    "    ! Allocate memory on the device\n",
    "    call hipcheck(hipMalloc(A_d, M, N))\n",
    "    call hipcheck(hipMalloc(B_d, M, N))\n",
    "    call hipcheck(hipMalloc(C_d, M, N))\n",
    "```\n",
    "\n",
    "There are additional ways to allocate memory with Fortran pointers. For example we could have used the `hipmalloc_r4_c_size_t` function to allocate the 2D arrays, each element using 4 bytes, and having integer variables of kind `c_size_t` to specify dimensions.\n",
    "\n",
    "\n",
    "```Fortran\n",
    "    ! Could have also done this for the allocate instead\n",
    "    call hipcheck(hipMalloc_r4_2_c_size_t(A_d, int(M_in, c_size_t), int(N_in, c_size_t)))\n",
    "    call hipcheck(hipMalloc_r4_2_c_size_t(B_d, int(M_in, c_size_t), int(N_in, c_size_t)))\n",
    "    call hipcheck(hipMalloc_r4_2_c_size_t(C_d, int(M_in, c_size_t), int(N_in, c_size_t)))\n",
    "```\n",
    "\n",
    "It is **important** to note that while Fortran pointers can be used as a **handle** on GPU memory allocations, they can't actually be used to access the GPU allocation from within Fortran code on the host. For example this would result in a memory access violation.\n",
    "\n",
    "```Fortran\n",
    "A_d(1,1) = 1.0\n",
    "```\n",
    "\n",
    "The reason is that when allocating with `hipMalloc`, the actual allocation is part of the **memory space on the GPU** and **not on the host**. Using Fortran pointers to access memory allocated with `hipMallocManaged` **is permissible**, because managed memory permits access from both GPU and the host."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162382e-f17a-47a3-b5e3-c626784b34ec",
   "metadata": {},
   "source": [
    "### De-allocate device memory\n",
    "\n",
    "When device memory is no longer needed, the **hipFree** function deallocates device memory with both C and Fortran pointers. We do this at the end of the program.\n",
    "\n",
    "```Fortran\n",
    "    ! Free allocations on the GPU\n",
    "    call hipcheck(hipFree(A_d))\n",
    "    call hipcheck(hipFree(B_d))\n",
    "    call hipcheck(hipFree(C_d))\n",
    "```\n",
    "\n",
    "It is **best practice** to make sure pointers are set to null when they no longer point to something. For Fortran pointers ([tensoradd_hip_fptr.f90](tensoradd_hip_fptr.f90)) we use the `nullify` function\n",
    "\n",
    "```Fortran\n",
    "    ! It is best practice to nullify all pointers \n",
    "    ! once we are done with them \n",
    "    nullify(A_h, B_h, C_h, A_d, B_d, C_d)\n",
    "```\n",
    "\n",
    "and for C pointers ([tensoradd_hip_cptr.f90](tensoradd_hip_cptr.f90)) we set them to `c_null_ptr`.\n",
    "\n",
    "```Fortran\n",
    "    ! Set C pointers to null as well\n",
    "    A_d = c_null_ptr\n",
    "    B_d = c_null_ptr\n",
    "    C_d = c_null_ptr\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882295bc-4ff5-4368-8788-caa3f859cabb",
   "metadata": {},
   "source": [
    "## Memory copies between host and device\n",
    "\n",
    "Memory can be copied between host and device allocations, or between device allocations. After filling arrays **A_h** and **B_h** we proceed to copy them to the device allocations **A_d** and **B_d**.\n",
    "\n",
    "### Copy from host to device\n",
    "\n",
    "The `hipMemcpy` function can use either C pointers or Fortran pointers. Here is the code to copy from host to device using C pointers.\n",
    "\n",
    "```Fortran\n",
    "    ! Copy memory from the host to the device \n",
    "    call hipcheck(hipMemcpy(A_d, c_loc(A_h), int(sizeof(A_h), c_size_t), hipMemcpyHostToDevice))\n",
    "    call hipcheck(hipMemcpy(B_d, c_loc(B_h), int(sizeof(B_h), c_size_t), hipMemcpyHostToDevice))\n",
    "```\n",
    "\n",
    "Each `hipmemcpy` call has a additional flag to specify the direction of the copy. There are five options available:\n",
    "\n",
    "* `hipMemcpyHostToHost`\n",
    "* `hipMemcpyHostToDevice`\n",
    "* `hipMemcpyDeviceToHost`\n",
    "* `hipMemcpyDeviceToDevice`\n",
    "* `hipMemcpyDefault`\n",
    "\n",
    "The `hipMemcpyDefault` option tries to infer the direction of transfer from the memory spaces of the input pointers. It is less readable however.\n",
    "\n",
    "Hipmemcpy also works with Fortran pointers, though when specifying the size to copy we specify **elements** instead of **bytes**! Notice the use of `size` instead of `sizeof` to specify elements instead of bytes.\n",
    "\n",
    "```Fortran\n",
    "    call hipcheck(hipMemcpy(A_d, A_h, size(A_h), hipMemcpyHostToDevice))\n",
    "    call hipcheck(hipMemcpy(B_d, B_h, size(B_h), hipMemcpyHostToDevice))\n",
    "```\n",
    "\n",
    "In the case of Fortran pointers we could have also used `hipMemcpy` functions that are specific to the arrays in question, for example we could also have done this.\n",
    "\n",
    "```Fortran\n",
    "    ! Could also have done this for the copy instead\n",
    "    !call hipcheck(hipMemcpy_r4_2_c_size_t(A_d, A_h, &\n",
    "    !    int(size(A_h), c_size_t), hipMemcpyHostToDevice))\n",
    "    !call hipcheck(hipMemcpy_r4_2_c_size_t(B_d, B_h, &\n",
    "    !    int(size(B_h), c_size_t), hipMemcpyHostToDevice))\n",
    "```\n",
    "\n",
    "### Copy from device to host\n",
    "\n",
    "After running the kernel, we copy **C_d** back to **C_h**, using either C pointers,\n",
    "\n",
    "```Fortran\n",
    "    ! Copy memory from the device to the host\n",
    "    call hipcheck(hipMemcpy(c_loc(C_h), C_d, sizeof(C_h), hipMemcpyDeviceToHost))\n",
    "```\n",
    "or Fortran pointers\n",
    "\n",
    "```Fortran\n",
    "    ! Copy from the device result back to the host\n",
    "    call hipcheck(hipMemcpy(C_h, C_d, size(C_d), hipMemcpyDeviceToHost))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914889ca-e7fe-4cbb-ac5f-adb6353039c4",
   "metadata": {},
   "source": [
    "## Kernel source and launch\n",
    "\n",
    "### Call the kernel launch function\n",
    "\n",
    "Since the Hipfort API doesn't have the functionality to define and launch kernels, we use the C function `launch_kernel_hip` to launch the kernel. This function has as the input argument C pointers for **A**, **B**, and **C** on the device and the integers **M** and **N** for the array sizes. In [tensoradd_hip_cptr.f90](tensoradd_hip_cptr.f90) we can just use the pointers **A_d**, **B_d**, and **C_d** directly while taking special care to convert the integer arguments to the type required by the function.\n",
    "\n",
    "```Fortran\n",
    "    ! Call the C function that launches the kernel\n",
    "    call launch_kernel_hip( &\n",
    "        A_d, &\n",
    "        B_d, &\n",
    "        C_d, &\n",
    "        int(M, c_int), &\n",
    "        int(N, c_int) &\n",
    "    )\n",
    "```\n",
    "\n",
    "In [tensoradd_hip_fptr.f90](tensoradd_hip_fptr.f90) we must use `c_loc` to get the C pointer that underlies the Fortran pointers.\n",
    "\n",
    "```Fortran\n",
    "    ! Call the C function that launches the kernel\n",
    "    call launch_kernel_hip( &\n",
    "        c_loc(A_d), &\n",
    "        c_loc(B_d), &\n",
    "        c_loc(C_d), &\n",
    "        int(M, c_int), &\n",
    "        int(N, c_int) &\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187937e6-8f0b-4e5e-8e5f-f761c06aef33",
   "metadata": {},
   "source": [
    "### Kernel launch function\n",
    "\n",
    "Let's examine the file [kernel_code.cpp](kernel_code.cpp). \n",
    "\n",
    "#### C linkage\n",
    "\n",
    "The kernel launch function `launch_kernel_hip` is wrapped in an `extern \"C\"` code block to ensure the function is compiled with C linkage. This mean it's name doesn't get mangled during compilation and is therefore accessible from Fortran.\n",
    "\n",
    "```C++\n",
    "// C function to call the tensoradd_2D kernel\n",
    "extern \"C\" {\n",
    "\n",
    "    void launch_kernel_hip(\n",
    "            float_type* A, \n",
    "            float_type* B,\n",
    "            float_type* C,\n",
    "            int M,\n",
    "            int N) {\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af9f921-8248-4b85-8e1b-7a30286a3f02",
   "metadata": {},
   "source": [
    "#### Role of the kernel launch function\n",
    "\n",
    "From the **GPU Computing Fundamentals** section we have the following diagram of a Grid that is made up of Blocks.\n",
    "\n",
    "<figure style=\"margin: 1em; margin-left:auto; margin-right:auto; width:90%;\">\n",
    "    <img src=\"../images/Grid.svg\">\n",
    "    <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">A Grid in the context of GPU computing. Grids are made up of Blocks and Blocks are made up of Threads</figcaption>\n",
    "</figure>\n",
    "\n",
    "It is the job of the kernel launch function to: \n",
    "\n",
    "* Pass arguments to the kernel \n",
    "* Determine the block size, (number of threads along each dimension of the block)\n",
    "* Determine the grid size, (number of blocks along each dimension of the grid)\n",
    "* Launch the kernel and examine launch errors\n",
    "* Optionally synchronize the device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0875bd-6179-417c-beb3-21ee244c4481",
   "metadata": {},
   "source": [
    "#### Define block size and grid size\n",
    "\n",
    "The `dim3` structure (with fields `x`, `y`, `z`) is used to specify the block size and the number of blocks per dimension.\n",
    "\n",
    "```C++       \n",
    "        // Grid size\n",
    "        dim3 global_size = {\n",
    "            (uint32_t)(M), \n",
    "            (uint32_t)(N)\n",
    "        }; \n",
    "        \n",
    "        // Block size, \n",
    "        dim3 block_size = {8,8,1};\n",
    "        \n",
    "        // Number of blocks in each dimension\n",
    "        dim3 nblocks = {\n",
    "            global_size.x/block_size.x,\n",
    "            global_size.y/block_size.y,\n",
    "            1\n",
    "        };\n",
    "```\n",
    "\n",
    "We must always have an integer number of blocks along every dimension of the grid. Sometimes this means making a grid that is larger than we need. This is fine provided we **build memory access protection into the kernel** so we don't run off the end of the arrays. \n",
    "    \n",
    "```C++\n",
    "        // Make sure there are enough blocks\n",
    "        if (global_size.x % block_size.x) nblocks.x += 1;\n",
    "        if (global_size.y % block_size.y) nblocks.y += 1;\n",
    "        if (global_size.z % block_size.z) nblocks.z += 1;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e742a-999a-40a3-85bd-9f14e58054b2",
   "metadata": {},
   "source": [
    "#### Shared memory\n",
    "\n",
    "HIP provides the ability to define a small amount of **shared memory** that is available to all threads in a block. This memory is fast and can be used as a small scratch space. We don't need shared memory for this example so we specify `0` as the number of bytes to allocate for shared memory.\n",
    "\n",
    "\n",
    "```C++\n",
    "        // Decide on the number of bytes to allocate for shared memory\n",
    "        size_t sharedMemBytes = 0;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d88363b-67f6-4653-b1a0-dead7efddd87",
   "metadata": {},
   "source": [
    "#### Kernel launch with hipLaunchKernelGGL\n",
    "\n",
    "Finally we get to launch the kernel itself. There are a few ways to do this, here we use the **hipLaunchKernelGGL** macro to launch the kernel `tensoradd_2D` with the specified block and grid size along with kernel arguments. A `stream` in HIP can be thought of as a work queue to which we submit work, we use stream 0 which is the default or null stream.\n",
    "\n",
    "```C++\n",
    "        // Launch the kernel\n",
    "        hipLaunchKernelGGL(\n",
    "                // Kernel name\n",
    "                tensoradd_2D,\n",
    "                // Number of blocks per dimension\n",
    "                nblocks,\n",
    "                // Number of threads along each dimension of the block\n",
    "                block_size,\n",
    "                // Number of bytes dynamically allocated for shared memory\n",
    "                sharedMemBytes,\n",
    "                // Stream to use (0 is the default or null stream)\n",
    "                0,\n",
    "                // Kernel arguments\n",
    "                A, B, C,\n",
    "                M, N);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f665ae4-f446-4cb2-b4b3-e485a482d0b4",
   "metadata": {},
   "source": [
    "#### Kernel launch with CUDA syntax\n",
    "\n",
    "One can also use the CUDA-like triple-chevron syntax to launch a kernel. This is not ANSI C++ compliant, however it isn't much of a problem because only compilers that understand triple chevrons (hipcc, nvcc) will be used to compile this source file.\n",
    "\n",
    "```C++\n",
    "        // The triple-chevron (non C++ compliant) way of launching kernels\n",
    "        tensoradd_2d<<<nblocks, block_size, sharedMemBytes, 0>>>(A, B, C, M, N);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0bc8d8-46e6-4960-85ae-82b5065fda74",
   "metadata": {},
   "source": [
    "#### Check kernel launch\n",
    "\n",
    "We use the `hipGetLastError` function to see if there were any problems arising from kernel launch. The macro `HIPCHECK` is defined earlier in the file [kernel_code.cpp](kernel_code.cpp) and behaves similarly to the Fortran subroutine `hipcheck` defined in `hipfort_check`.\n",
    "\n",
    "```C++\n",
    "        // Make sure the kernel launch went ok\n",
    "        HIPCHECK(hipGetLastError());\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9245c51a-eea6-4ec9-963e-5405ed12080d",
   "metadata": {},
   "source": [
    "#### Synchronize the compute device\n",
    "\n",
    "Finally, we use the `hipDeviceSynchronize` function to make sure that the kernel is finished before continuing. This step is not strictly necessary because the subsequent copy of **C_d** to **C_h** will use the same (null) stream and will block until the kernel is finished. \n",
    "\n",
    "```C++\n",
    "    \t// Wait for the kernel to finish\n",
    "    \tHIPCHECK(hipDeviceSynchronize()); \n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb8967-44ea-405f-9056-ba69aa799c5a",
   "metadata": {},
   "source": [
    "### Kernel source \n",
    "\n",
    "Let's examine the source of the kernel we are launching to perform 2D tensor addition.  Notice that kernel code is always a function with a return type of `void` and has the `__global__` qualifier. This qualifier means the function can be launched from the host and will run on the device. Other qualifiers such as `__host__` or `__device__` permit the function to also be used on the host or called from a kernel on the device.\n",
    "\n",
    "```C++\n",
    "// Kernel to perform 2D tensor addition\n",
    "__global__ void tensoradd_2D (\n",
    "\t    // Memory allocations\n",
    "        float_type* A, \n",
    "        float_type* B, \n",
    "        float_type* C,\n",
    "        // Size of the problem\n",
    "        int M,\n",
    "        int N) {\n",
    "\n",
    "    // Any dynamically allocated memory is available here\n",
    "    extern __shared__ float_type shared[];\n",
    "\n",
    "    // We adopt column-major indexing for this example\n",
    "    \n",
    "    // Compute (zero-based) indicies within grid\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "    // Due to block sizes \n",
    "    // i and j might lie outside M and N\n",
    "    // make sure we don't run off the domain\n",
    "    // of the grid\n",
    "    if ((i<M) && (j<N)) {\n",
    "        // 1D position within 2D arrays\n",
    "        // stride down a column is 1\n",
    "        // stride along a row is M\n",
    "        \n",
    "        size_t offset = i + j*M;\n",
    "\n",
    "        // Now perform the 2D tensor addition\n",
    "        C[offset] = A[offset] + B[offset];\n",
    "    }\n",
    "}\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e532de6-069a-4a99-b459-a7adcde14af5",
   "metadata": {},
   "source": [
    "#### Kernel arguments\n",
    "\n",
    "We define pointers **A**, **B**, **C** to memory of `float_type` as inputs to the kernel. These are pointers to memory allocations in the **global** memory space on the compute device. In the host program we pass in the pointers **A_d**, **B_d**, **C_d** for use in the kernel as **A**, **B**, **C**. We also pass in the integers **M** and **N** that represent the size of the 2D tensors.\n",
    "\n",
    "```C++\n",
    "// Kernel to perform 2D tensor addition\n",
    "__global__ void tensoradd_2D (\n",
    "\t    // Memory allocations\n",
    "        float_type* A, \n",
    "        float_type* B, \n",
    "        float_type* C,\n",
    "        // Size of the problem\n",
    "        int M,\n",
    "        int N) {\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066a08d-35b3-4a2b-9df7-be42365f099e",
   "metadata": {},
   "source": [
    "#### Shared memory\n",
    "\n",
    "Any shared memory that we specified in the kernel launch function is available through this line of code where we make shared memory available as a pointer to an array of type `char`. \n",
    "\n",
    "```C++\n",
    "    // Any dynamically allocated memory is available here\n",
    "    extern __shared__ char shared[];\n",
    "```\n",
    "\n",
    "We can only have one line of code that points to `extern __shared__` but we can declare pointers of any type that points to any location within this space. For example we could define a pointer called `shared_A` of type `float_type*` that points to the first element of the shared memory, like this.\n",
    "\n",
    "```C++\n",
    "    // Can use shared memory like this\n",
    "    float_type* shared_A = (float_type*)&shared[0];\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5b483a-1a26-48f2-952d-c86f6140eca4",
   "metadata": {},
   "source": [
    "#### Locate the kernel within the grid\n",
    "\n",
    "Within kernel code there are structures that can help us locate the kernel's position within the Grid at launch. Each structure has fields `{x, y, z}` that each contain a value for its index or length along the corresponding dimension in the grid.\n",
    "\n",
    "| Structure | Explanation |\n",
    "| --- | --- |\n",
    "| gridDim | Number of blocks along each dimension of the grid. |\n",
    "| blockIdx | Index of a block along a dimension of the grid. |\n",
    "| blockDim | Number of threads along a dimension of a block. |\n",
    "| threadIdx | Index of a thread along a dimension of the block. |\n",
    "\n",
    "We use these structures to find the `(i, j)` coordinates of the kernel within the grid.\n",
    "\n",
    "```C++\n",
    "    // Compute (zero-based) indicies within grid\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b9fd13-ebf5-404d-a46f-c3b03afd4732",
   "metadata": {},
   "source": [
    "#### Kernel math and array indexing\n",
    "\n",
    "At last! In the last lines of the kernel we can perform the actual 2D vector addition. Since the grid might be larger than the size of the 2D arrays, then some indices `(i,j)` may lie **outside** the bounds of **M** and **N**, depending on the choice of the block size. Therefore we enclose the kernel code within a protective `if` statement.\n",
    "\n",
    "```C++\n",
    "    if ((i<M) && (j<N)) {\n",
    "        // 1D position within 2D arrays\n",
    "        // stride down a column is 1\n",
    "        // stride along a row is M\n",
    "        \n",
    "        size_t offset = i + j*M;\n",
    "\n",
    "        // Now perform the 2D tensor addition\n",
    "        C[offset] = A[offset] + B[offset];\n",
    "    }\n",
    "```\n",
    "\n",
    "From the **GPU Computing Fundamentals** section, the position (offset) in a multi-dimensional allocation is given by $p=C \\cdot S$, where $C$ is the coordinates and $S$ is the stride vector. The tensors are of size $(M,N)$, and we are using column-major indexing, therefore the stride vector is $(1, M)$. Given the coordinates are $C=(i,j)$ the `offset` is $(i,j) \\cdot (1, M)= i \\times 1 + j \\times M = i + j \\times M$. \n",
    "\n",
    "```C++\n",
    "    size_t offset = i + j*M;\n",
    "```\n",
    "\n",
    "We use this offset to perform 2D tensor addition. Note that in C/C++ kernel code we use the square operator `[]` to access memory relative to a pointer, and indices are 0-based.\n",
    "\n",
    "```C++\n",
    "    // Now perform the 2D tensor addition\n",
    "    C[offset] = A[offset] + B[offset];    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b5a3fd-8a35-41b0-8ea3-fc6cc00edaf5",
   "metadata": {},
   "source": [
    "## Code validation\n",
    "\n",
    "In <a href=\"../src/math_utils.f90\">../src/math_utils.f90</a> we have imported the checking function `check_tensor_addition_2D` as `check`. We call this function to see if the computation was valid. The function will print an error and exit if the result in `C_h(i,j)` is not within `eps_mult` floating point spacings of `A_h(i,j)+B_h(i,j)`.\n",
    "\n",
    "```Fortran\n",
    "    ! Check the answer\n",
    "    success = check(A_h, B_h, C_h, eps_mult)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3608616-95bf-453f-8bd4-f35ed1bc39f5",
   "metadata": {},
   "source": [
    "## Resource cleanup\n",
    "\n",
    "We have already covered the importance of using `hipFree` to deallocate any memory allocations created with `hipMalloc` followed by making Fortan pointers safe through using either `nullify`, and C pointers safe by setting to c_null_ptr. We finish with a call `reset_device` to make sure the GPU is finished work, and that all allocations have been cleaned up and the primary context is in a fresh state.\n",
    "\n",
    "```Fortran\n",
    "    ! Make sure all resources on the selected device are released\n",
    "    call reset_device\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3615d12d-72cc-472e-8660-49654962c510",
   "metadata": {},
   "source": [
    "## Memory safety with device allocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c22ff3-59c6-4441-afaa-dc73d0f64fda",
   "metadata": {},
   "source": [
    "As you might have noticed there are **numerous** opportunities for memory errors to arise with this code. For example, bugs can creep in if we:\n",
    "\n",
    "* Don't check the return result on all API calls. This can result in **silent failures**.\n",
    "* Don't specify the correct number of bytes or elements for memory allocations.\n",
    "* Don't specify the correct number of bytes or elements when copying memory.\n",
    "* Don't use guard clauses, or correct indexing math in kernels, and then try to use memory beyond device allocations. \n",
    "* Are not consistent with precision when passing data from Fortran to C, and from C to the kernel. This is a source of bugs that are **really hard** to diagnose.\n",
    "* Don't initialize or copy memory when we should. Reading from allocated but uninitialized memory can result in extreme values in the output!\n",
    "* Forget to deallocate pointers. This is a **memory leak**!\n",
    "* Try to access memory through a Fortran pointer when the underling allocation is on the GPU.\n",
    "* Forget to set pointers to null and then try to use them. This is called a **dangling pointer**.\n",
    "\n",
    "### Memory safety issues with C pointers\n",
    "\n",
    "The C pointer method is quite powerful in that the `c_loc` function can produce C pointers from all kinds of Fortran pointers and arrays with the `target` attribute. However with C pointers the size and data type information are decoupled from the pointer, leaving it to the programmer to make sure this information is paired with the pointer in any function calls.\n",
    "\n",
    "### Memory safety issues with Fortran pointers\n",
    "\n",
    "Fortran pointers are safer in that the size and data type of the allocation is encoded into the pointer as well as information on wether or not it is associated (pointing at a memory allocation). This provides opportunities for additional consistency checks when working with memory. As with C pointers, Fortran pointers are still vulnerable to memory leaks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fdada4-faa6-407b-98e8-0a5ca7e0daa5",
   "metadata": {},
   "source": [
    "## Use modern Fortran features for additional memory safety\n",
    "\n",
    "The introduction of the Fortran 90 standard brought with it some object oriented features such as `derived types`, which are like C `structs` and have many object-oriented features seen in C++ classes, such type-bound procedures (subroutines that operate on internal data) and a `final` subroutine (destructor) that is called when an instance of the derived type goes out of scope. Types also can have `generic procedures` which are mappings so that one function name can map to many different functions, depending on the input data type. We can use derived types to build **additional safety** into working with memory allocations on a compute device. \n",
    "\n",
    "### Fortran types (classes)\n",
    "\n",
    "In the file [tensor_hip.f90](tensor_hip.f90) is a `tensor` type whose memory allocation is on the compute device. It contains just three fields, a flag `allocd` to keep track of wether or not the memory is allocated, a C pointer named `mem` to contain the allocation, and an integer `nbytes` of kind `c_size_t` to keep track of the number of bytes allocated.\n",
    "\n",
    "```Fortran \n",
    "    type :: tensor\n",
    "        !! Object to represent a tensor allocated on the GPU\n",
    "\n",
    "        ! Is this tensor allocated?\n",
    "        logical :: allocd = .false.\n",
    "        \n",
    "        ! Pointer to the memory\n",
    "        type(c_ptr) :: mem = c_null_ptr\n",
    "        \n",
    "        ! Number of bytes in the allocation\n",
    "        integer(c_size_t) :: nbytes = 0\n",
    "```\n",
    "\n",
    "Following the `contains` clause we can define procedures that on internal data of the type. These procedures are just subroutines that work on the internal data of the type.\n",
    "\n",
    "```Fortran    \n",
    "        contains\n",
    "        \n",
    "            ! Upload procedures\n",
    "            procedure :: copy_from_host_cptr\n",
    "            procedure :: copy_from_host_float_type_1\n",
    "            procedure :: copy_from_host_float_type_2\n",
    "            \n",
    "            ! Download procedures\n",
    "            procedure :: copy_to_host_cptr\n",
    "            procedure :: copy_to_host_float_type_1\n",
    "            procedure :: copy_to_host_float_type_2\n",
    "            \n",
    "            ! Allocation and de-allocation procedures\n",
    "            procedure :: malloc\n",
    "            procedure :: free\n",
    "```\n",
    "\n",
    "Generic procedures are a way to provide polymorphism, a single procedure that can map to many procedures depending on the input arguments. We define two generic procedures `copy_from` and `copy_to` that copy arrays from the host to the tensor and from the tensor to the host for different types of input arguments. These map to the `copy_to` and `copy_from` procedures defined above.\n",
    "\n",
    "```Fortran\n",
    "! Generic procedures for different types of data\n",
    "            generic :: copy_from => copy_from_host_cptr, &\n",
    "                copy_from_host_float_type_1, &\n",
    "                copy_from_host_float_type_2 !, can specify more comma-separated functions here\n",
    "            generic :: copy_to => copy_to_host_cptr, &\n",
    "                copy_to_host_float_type_1, &\n",
    "                copy_to_host_float_type_2 !, can specify more comma-separated functions here\n",
    "```\n",
    "\n",
    "A `final` procedure is called when an instance of this type goes out of scope. It functions as a **destructor** for the type. We can use it to make sure the memory allocation is always cleaned up when the object is destroyed.\n",
    "\n",
    "```Fortran    \n",
    "            ! Final is a cleanup function when the object goes out of scope\n",
    "            final :: destructor\n",
    "            \n",
    "end type tensor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f400a-587c-47b7-ad57-139221161182",
   "metadata": {},
   "source": [
    "#### Procedures\n",
    "\n",
    "Within the [tensor_hip.f90](tensor_hip.f90) module are the subroutines and functions that the procedures refer to. Since the allocation status and number of bytes is defined within the type, this gives us opportunities to perform additional memory safety checks. For example the `malloc` procedure is defined as follows:\n",
    "\n",
    "```Fortran\n",
    "    ! Functions for the tensor class\n",
    "    subroutine malloc(this, nbytes)\n",
    "        !! Allocate memory for a tensor on the GPU\n",
    "        \n",
    "        ! Import the HIP modules\n",
    "        use hipfort\n",
    "        use hipfort_check\n",
    "\n",
    "        ! Polymorphic variable for the class\n",
    "        class(tensor), intent(inout) :: this\n",
    "\n",
    "        ! Number of bytes to allocate\n",
    "        integer(c_size_t), intent(in) :: nbytes\n",
    "\n",
    "        ! Check to make sure we are not already allocated\n",
    "        if (this%allocd) then\n",
    "            call this%free\n",
    "        end if\n",
    "\n",
    "        ! Now allocate memory for the tensor on the GPU\n",
    "        call hipCheck(hipMalloc(this%mem, nbytes))\n",
    "\n",
    "        ! Set the allocated flag\n",
    "        this%allocd = .true.\n",
    "\n",
    "        ! Set the number of bytes in the allocation\n",
    "        this%nbytes = nbytes\n",
    "        \n",
    "    end subroutine malloc\n",
    "```\n",
    "\n",
    "In a similar way to Python class member functions, procedures of a type in Fortran always have at least one argument called `this` which is of `class(tensor)`. The `class(tensor)` type is a polymorphic placeholder for both the `tensor` type and any types that inherit from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df732e6b-26de-4b36-b675-5f6cd9a5edc6",
   "metadata": {},
   "source": [
    "#### Access to type members and procedures\n",
    "\n",
    "Access to any members and procedures of the type is through the `%` operator. For example within the `malloc` procedure we check the `allocd` variable and run the `free` procedure as follows:\n",
    "\n",
    "```Fortran\n",
    "    ! Check to make sure we are not already allocated\n",
    "    if (this%allocd) then\n",
    "        call this%free\n",
    "    end if\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22052be1-38cd-4f10-925d-a2d05d4b12b6",
   "metadata": {},
   "source": [
    "#### Final procedure\n",
    "\n",
    "The `final` procedure (which we name as `destructor`) needs to have `this` as an argument of `type(tensor)` to signify that it **must** be specific instance of the `tensor` class. In this subroutine we just call the `free` procedure to free memory when a tensor goes out of scope. This is a way to ensure that the memory allocation on the compute device is always released on exit.\n",
    "\n",
    "```Fortran\n",
    "subroutine destructor(this)\n",
    "    !! Destructor, `this` must be of type(tensor) because it is valid only for instances\n",
    "    !! of this type\n",
    "    type(tensor), intent(inout) :: this\n",
    "    call this%free\n",
    "end subroutine destructor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baae7cf8-6459-4812-a3eb-a64ff60a73db",
   "metadata": {},
   "source": [
    "### Using the tensor type\n",
    "\n",
    "In the source file [tensoradd_hip_oo.f90](tensoradd_hip_oo.f90) we use the `tensor` type to work with memory allocations on the GPU in a way that has enhanced memory safety and fewer chances of bugs being introduced. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f6f87-40e7-4d46-ba49-d81dd6ddd9c6",
   "metadata": {},
   "source": [
    "#### Import the tensor type\n",
    "\n",
    "We bring in the tensor type and rename it to `tensor_gpu` with this statement.\n",
    "\n",
    "```Fortran\n",
    "    ! Use the tensor type defined in tensor_hip.f90\n",
    "    use tensor_hip, only : tensor_gpu => tensor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85233dc-254b-4232-bdc1-32a3c9a997c6",
   "metadata": {},
   "source": [
    "#### Define objects\n",
    "\n",
    "Then we define `A_d`, `B_d`, and `C_d` of type `tensor_gpu`\n",
    "\n",
    "```Fortran\n",
    "    ! Tensors on the GPU\n",
    "    type(tensor_gpu) :: A_d, B_d, C_d\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b754d119-dea0-4c0e-a65b-e642b452fca5",
   "metadata": {},
   "source": [
    "#### Allocate memory\n",
    "\n",
    "Memory allocations are performed using the `malloc` type procedure.\n",
    "\n",
    "```Fortran\n",
    "    ! Allocate memory for tensors, \n",
    "    ! see tensor_hip.f90 for \n",
    "    ! definition of generic procedures \n",
    "    call A_d%malloc(int(sizeof(A_h), c_size_t))\n",
    "    call B_d%malloc(int(sizeof(B_h), c_size_t))\n",
    "    call C_d%malloc(int(sizeof(C_h), c_size_t))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf78cf2-958f-45cf-a7bf-39da4403f99c",
   "metadata": {},
   "source": [
    "#### Copy memory from the host\n",
    "\n",
    "Copying memory from the host is performed using the generic `copy_from` procedure. Since we have a procedure `copy_from_host_c_float_2` that handles 2D Fortran pointers, this call will be routed to that procedure.  \n",
    "\n",
    "```Fortran\n",
    "    call A_d%copy_from(A_h)\n",
    "    call B_d%copy_from(B_h)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f35c3d3-017a-48b1-a313-d4bf5ed8c9fb",
   "metadata": {},
   "source": [
    "#### Kernel arguments\n",
    "\n",
    "When launching the kernel we just pass in the `mem` field of the tensor type.\n",
    "\n",
    "```Fortran\n",
    "    ! Call the C function that launches the kernel\n",
    "    call launch_kernel_hip( &\n",
    "        A_d%mem, &\n",
    "        B_d%mem, &\n",
    "        C_d%mem, &\n",
    "        int(M, c_int), &\n",
    "        int(N, c_int) &\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac61e31c-6b1b-4dd5-b899-125fb523e7e2",
   "metadata": {},
   "source": [
    "#### Copy memory to the host\n",
    "\n",
    "The copy back from `C_d` to `C_h` is accomplished with the `copy_to` generic procedure.\n",
    "\n",
    "```Fortran\n",
    "    ! Copy memory from the device to the host\n",
    "    call C_d%copy_to(C_h)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2eb011-5383-40b1-9a8a-25f2240f9109",
   "metadata": {},
   "source": [
    "#### Resource cleanup\n",
    "\n",
    "When it comes time to clean up the memory we call the `free` procedure.\n",
    "\n",
    "```Fortran\n",
    "    ! Free tensors on the device\n",
    "    ! this step is not necessary because \n",
    "    ! the tensor type has a destructor\n",
    "    ! that is called when the tensor is out of scope\n",
    "    call A_d%free\n",
    "    call B_d%free\n",
    "    call C_d%free\n",
    "```\n",
    "\n",
    "This step is not strictly necessary, as the destructor is automatically called when the tensors go out of scope. Then at cleanup we reset compute devices as per normal.\n",
    "\n",
    "```Fortran\n",
    "    ! Make sure all resources on the device are released\n",
    "    call reset_device\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc145f-79e5-4454-92e2-730ceba9b03d",
   "metadata": {},
   "source": [
    "<address>\n",
    "Written by Dr. Toby Potter of <a href=\"https://www.pelagos-consulting.com\">Pelagos Consulting and Education</a> and Dr. Joe Schoonover from <a href=\"https://www.fluidnumerics.com\">Fluid Numerics</a>. All trademarks mentioned in this page are the property of their prospective owners.\n",
    "</address> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
