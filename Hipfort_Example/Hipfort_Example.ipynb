{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e72da1e7-84c0-4e8a-81af-6fc0b2351727",
   "metadata": {},
   "source": [
    "# A complete Hipfort application\n",
    "\n",
    "In the **Fortran Refresher** section we covered the essentials of the Fortran language and how to use `subroutines`, `functions`, `pointers`, `modules` as well as how to call C code from Fortran. If this is unfamiliar, then it might be useful to review the material in that section first.\n",
    "\n",
    "From **GPU Computing Fundamentals** section, every accelerated application has the same basic design:\n",
    "\n",
    "1. At program launch compute devices are discovered and initialized.\n",
    "2. Memory spaces are allocated on the compute device.\n",
    "3. Kernels are prepared.\n",
    "4. Memory is copied from the host to the compute device.\n",
    "5. Kernels are run to perform whatever compute operation is required.\n",
    "6. The output from kernel runs is copied back from the compute device to the host. IO may then occur before the next iteration.\n",
    "  \n",
    "**Steps 4-6** are repeated as many times as neccessary until the program is done, then at completion of the program\n",
    "\n",
    "7. Deallocate memory, \n",
    "8. Release resources and exit.\n",
    "\n",
    "## Tensor addition math\n",
    "\n",
    "In this section we are going to walk through each of these steps as part of a complete example with Hipfort, using 2D tensor addition as the basic algorithm. For 2D tensors **A**, **B**, and **C**, each of size (M,N), the following relationship holds true at each index (i,j) in the tensors.\n",
    "\n",
    "$$\n",
    "A(i,j)+B(i,j)=C(i,j)\n",
    "$$\n",
    "\n",
    "In the prior **Fortran Refresher** section we used CPU code in Fortran and C to compute the answer $C(i)$ for 1D tensor addition. In this example we are going to use a HIP Kernel on the GPU to compute the answer $C(i,j)$ at every location in **C**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff9d013-3e39-4f66-a1be-2e2409f460d1",
   "metadata": {},
   "source": [
    "## Example applications\n",
    "\n",
    "In HIP we need a way to get a handle on the memory allocations that are on the compute device. Hipfort can use either a C pointer (`type(c_ptr)`) or a Fortran `pointer` as a handle to the memory allocations on the GPU. The methods of working with each type are subtly different though. In the applications \n",
    "\n",
    "* [tensoradd_hip_cptr.f90](tensoradd_hip_cptr.f90)\n",
    "* [tensoradd_hip_fptr.f90](tensoradd_hip_fptr.f90)\n",
    "\n",
    "we use C pointers and Fortran pointers to perform 2D tensor addition. It will be helpful to have **both files open** at the same time for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dd78fc-3fc9-43e3-8fda-ba5cd6f5d2cf",
   "metadata": {},
   "source": [
    "## Use the Hipfort API\n",
    "\n",
    "Access to all Hipfort functions is via the `hipfort` and `hipfort_check` modules. We bring those modules in along with others at the beginning of the program.\n",
    "\n",
    "```Fortran\n",
    "    ! HIP modules\n",
    "    use hipfort\n",
    "    use hipfort_check\n",
    "```\n",
    "\n",
    "## Check HIP API calls\n",
    "\n",
    "Hipfort functions usually have a **return type** that we can check to make sure everything worked ok. If these checks are **not performed** some functions will continue even though there has been a **silent failure**.  It is therefore **best practice** to **always** the check the return type from HIP calls. The `hipfort_check` module defines a subroutine called `hipcheck` that we can use to wrap around a HIP API call. It then checks the return type and exits the program if there has been an error. For example we wrap a `hipmalloc` call with hipcheck as follows:\n",
    "\n",
    "```\n",
    "call hipcheck(hipmalloc(A_d, M, N))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cdb596-6fdc-4d8d-adf0-aedc19fe6a2e",
   "metadata": {},
   "source": [
    "## Code validation\n",
    "\n",
    "It is important to make sure that the output of the compuation is accurate for every element in the output. A wrong answer can be computed very quickly but it is of no use! In the file [math_utils.f90](math_utils.f90) is a function called `check_tensor_addition_2D` that iterates over every point in the output tensor $C(i,j)$ and checks to see each point is within an error margin of $A(i,j)+B(i,j)$. The function has the following signature, where **A**, **B**, and **C** are arrays on the host. It has the following signature:\n",
    "\n",
    "```Fortran\n",
    "function check_tensor_addition_2D(A, B, C, eps_mult) result(success)\n",
    "            !! Function to check the outcome of tensor addition\n",
    "            !! only check the host arrays\n",
    "\n",
    "            real(kind=c_float), dimension(:,:), intent(in), pointer :: A, B, C\n",
    "        \n",
    "            real, intent(in) :: eps_mult\n",
    "                !! Epsilon multiplier, how many floating point spacings\n",
    "                !! can the computed answer be from our benchmark answer\n",
    "```\n",
    "\n",
    "and we import it as the function `check` within the two programs\n",
    "\n",
    "```Fortran\n",
    "! Maths check\n",
    "    use math_utils, only : check => check_tensor_addition_2D\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44821c62-8e74-4b72-aba0-b15b85f4fb6c",
   "metadata": {},
   "source": [
    "## Fortran interface to kernel launch function\n",
    "\n",
    "Hipfort doesn't yet have a way to launch kernels, however passing pointers from Fortran to C/C++ functions is straightforward, and from C/C++ code we can launch kernels. In the file [kernel_code.cpp](kernel_code.cpp) is a function called `launch_kernel_hip` that does the job of launching kernels. It has the following signature:\n",
    "\n",
    "```Fortran\n",
    "    void launch_kernel_hip(\n",
    "            float_type* A, \n",
    "            float_type* B,\n",
    "            float_type* C,\n",
    "            int M,\n",
    "            int N) {\n",
    "```\n",
    "\n",
    "and we have type defined `float_type` as `float` earlier in the file.\n",
    "\n",
    "```C++\n",
    "typedef float float_type;\n",
    "```\n",
    "\n",
    "In order to call this function from Fortran we define an `interface` to the function within the programs of [tensoradd_hip_cptr.f90](tensoradd_hip_cptr.f90) and [tensoradd_hip_fptr.f90](tensoradd_hip_fptr.f90) as follows:\n",
    "\n",
    "```Fortran\n",
    "    interface\n",
    "        ! A C function with void return type\n",
    "        ! is regarded as a subroutine in Fortran \n",
    "        subroutine launch_kernel_hip(A, B, C, M, N) bind(C)\n",
    "            use iso_c_binding\n",
    "            ! Fortran passes arguments by reference as the default\n",
    "            ! Arguments must have the \"value\" option present to pass by value\n",
    "            ! Otherwise launch_kernel will receive pointers of type void**\n",
    "            ! instead of void*\n",
    "            type(c_ptr), intent(in), value :: A, B, C\n",
    "            integer(c_int), intent(in), value :: M, N\n",
    "        end subroutine\n",
    "        \n",
    "    end interface\n",
    "\n",
    "```\n",
    "\n",
    "Note the presence of the `value` option for the input arguments. This is so we pass arguments by `value` instead of by **reference** (the default). If we didn't have the value keyword the C function would receive a reference (or pointer to the variables) instead of a copy of the variables. In the case of `launch_kernel_hip` without the `value` keyword in the interface then A would be of type `void**` instead of `void*`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594eb06-9d38-4651-a518-ba28488f379f",
   "metadata": {},
   "source": [
    "## Select and manage a HIP device\n",
    "\n",
    "Each HIP compute device has a resource manager called a `primary context` that keeps track of all the resources allocated on that device. Host threads share access to the primary contexts in a way that is (or at least is intended to be!) thread safe. This means that each host thread in an application is **free to choose** which device to use. Usually the HIP runtime is initialised (primary contexts are created) and a host thread is **connected** to the first available device (device 0) whenever that host thread makes its first call to a HIP function. For environments where there are multiple devices it is **good practice** to explicity initialize the HIP API and be specific about which device you would like the host thread to connect to. In the file [hip_utils.f90](hip_utils.f90) are two subroutines `init_gpu` and `reset_gpu` that provide a way to choose a GPU and reset (release all resources) in the selected device's primary context. The first statement after variable declarations in  [tensoradd_hip_cptr.f90](tensoradd_hip_cptr.f90) and [tensoradd_hip_fptr.f90](tensoradd_hip_fptr.f90) is to initialize HIP and choose the GPU.\n",
    "\n",
    "```Fortran\n",
    "    ! Find and set the GPU device. Use device 0 by default\n",
    "    call init_gpu(0)   \n",
    "```\n",
    "\n",
    "The argument to init_gpu is the desired index of the device that we'd like to use. Device indices start at 0 and in this instance we select the first available gpu with id 0.\n",
    "\n",
    "Inside the function `init_gpu` we initialize the HIP API using a call to `hipinit`.\n",
    "\n",
    "```Fortran\n",
    "call hipcheck(hipinit(0))\n",
    "```\n",
    "\n",
    "A call to `hipinit` only needs to be done once, so we have a variable `acquired` within the module to make sure of this. \n",
    "\n",
    "Next, we call `hipgetdevicecount` to poll the number of valid devices. If the desired index (the input argument to `init_gpu`) falls within the range of valid device then we call `hipsetdevice` to set the HIP device according to the desired device index. Any subsequent HIP calls from a host thread will then use the selected GPU.\n",
    "\n",
    "```Fortran\n",
    " ! Get the number of compute devices\n",
    "        call hipcheck(hipgetdevicecount(ndevices))\n",
    "            \n",
    "        if ((dev_id .ge. 0) .and. (dev_id .lt. ndevices)) then\n",
    "            ! Choose a compute device\n",
    "            call hipcheck(hipsetdevice(dev_id))\n",
    "        else\n",
    "            write(error_unit,*) 'Error, dev_id was not inside the range of available devices.'\n",
    "            stop 1\n",
    "        end if\n",
    "```\n",
    "\n",
    "The function `reset_gpu` in [hip_utils.f90](hip_utils.f90) calls `hipdevicesynchronize` to make sure the selected GPU device is finished with all pending activity, then it calls `hipdevicereset` to release all resources in the primary context. \n",
    "\n",
    "```Fortran\n",
    "        ! Release all resources on the gpu\n",
    "        if (acquired) then\n",
    "            ! Make sure the GPU is finished\n",
    "            ! with all pending activity\n",
    "            call hipcheck(hipdevicesynchronize())\n",
    "\n",
    "            ! Now free all resources on the primary context\n",
    "            ! of the selected GPU\n",
    "            call hipcheck(hipdevicereset())\n",
    "        end if\n",
    "```\n",
    "\n",
    "It is **best practice** to reset the compute device at the end of the computation, but make sure that no other threads are using resources on that GPU when you do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f2d9f-7768-40ed-a613-0f7397e7d99d",
   "metadata": {},
   "source": [
    "## Memory allocation and de-allocation\n",
    "\n",
    "### Standard data types on the host\n",
    "\n",
    "Next, we allocate memory for the tensors on both the host and the compute device. Fortran has the ability to change, with a compiler flag, how many bytes are used `real` and `integer` types. HIP kernels need fixed data types, so when you allocate arrays that will be used to interact with device allocations, it is **best practice** in Fortran code to use array data types whose number of bytes **do not change**. We use the `c_float` kind from the `iso_c_binding` module to make sure the host arrays are of the data type that is synonymous with `float` in C code.\n",
    "\n",
    "```Fortran\n",
    "real(kind=c_float), dimension(:,:), pointer :: A_h, B_h, C_h\n",
    "\n",
    "! Allocate memory on host \n",
    "allocate(A_h(M,N), B_h(M, N), C_h(M,N))\n",
    "```\n",
    "\n",
    "### Variable naming convention\n",
    "\n",
    "Notice the `_h` suffix on variable names. In this module we choose to put a `_h` suffix on memory allocations that reside on the host and a `_d` suffix for memory allocations that reside on the compute device. It is a variable naming convention that makes it easier to see what memory is allocated where."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe3074-8276-4110-b1b9-76d98893e95b",
   "metadata": {},
   "source": [
    "### C pointers and Fortran pointers for device allocations\n",
    "\n",
    "Both C pointers (`type(c_ptr)`) and Fortran pointers can be used as handles to memory allocations on the compute device. C pointers are flexible but not very safe. Fortran pointers are also not very safe but additionally  retain information on the shape, data type, and size of the allocation.\n",
    "\n",
    "In [tensoradd_hip_cptr.f90](tensoradd_hip_cptr.f90) we use C pointers for memory allocations to tensors **A**, **B**, and **C** on the compute device\n",
    "\n",
    "```Fortran\n",
    "    ! C Pointers to memory allocations on the device\n",
    "    type(c_ptr) :: A_d, B_d, C_d\n",
    "```\n",
    "\n",
    "and in [tensoradd_hip_fptr.f90](tensoradd_hip_fptr.f90) we use Fortran pointers.\n",
    "\n",
    "```Fortran\n",
    "    ! Fortran pointers to memory allocations on the device\n",
    "    real(kind=c_float), dimension(:,:), pointer :: A_d, B_d, C_d\n",
    "```\n",
    "\n",
    "### Allocate device memory\n",
    "\n",
    "The `hipmalloc` function allocates memory in the **global** memory space on the compute device. This memory is the largest (and slowest) memory on the compute device. Memory allocated with `hipmalloc` is accessible from every kernel that runs on the compute device but not from the host. \n",
    "\n",
    "When using hipmalloc with **C pointers** we need to specify how many bytes to reserve. The `sizeof` function returns the number of bytes allocated for a Fortran pointer. In [tensoradd_hip_cptr.f90](tensoradd_hip_cptr.f90) we use the bytes allocated for the host arrays as an input argument when allocating **A_d**, **B_d**, and **C_d**.\n",
    "\n",
    "```Fortran\n",
    "    ! Allocate tensors on the GPU\n",
    "    call hipcheck(hipmalloc(A_d, sizeof(A_h)))\n",
    "    call hipcheck(hipmalloc(B_d, sizeof(B_h)))\n",
    "    call hipcheck(hipmalloc(C_d, sizeof(C_h)))\n",
    "```\n",
    "\n",
    "Fortran pointers need **elements** (not bytes) as the input argument for allocation with `hipmalloc`. In [tensoradd_hip_fptr.f90](tensoradd_hip_fptr.f90) we specify the size of the arrays to allocate in elements along each dimension.\n",
    "\n",
    "```Fortran\n",
    "    ! Allocate memory on the GPU\n",
    "    call hipcheck(hipmalloc(A_d, M, N))\n",
    "    call hipcheck(hipmalloc(B_d, M, N))\n",
    "    call hipcheck(hipmalloc(C_d, M, N))\n",
    "```\n",
    "\n",
    "There are additional ways to allocate memory with Fortran pointers. For example we could have used the `hipmalloc_r4_c_size_t` function to allocate the 2D arrays, each element using 4 bytes, and having integer variables of kind `c_size_t` to specify dimensions.\n",
    "\n",
    "\n",
    "```Fortran\n",
    "    ! Could have also done this for the allocate instead\n",
    "    call hipcheck(hipmalloc_r4_2_c_size_t(A_d, int(M_in, c_size_t), int(N_in, c_size_t)))\n",
    "    call hipcheck(hipmalloc_r4_2_c_size_t(B_d, int(M_in, c_size_t), int(N_in, c_size_t)))\n",
    "    call hipcheck(hipmalloc_r4_2_c_size_t(C_d, int(M_in, c_size_t), int(N_in, c_size_t)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882295bc-4ff5-4368-8788-caa3f859cabb",
   "metadata": {},
   "source": [
    "## Memory copies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914889ca-e7fe-4cbb-ac5f-adb6353039c4",
   "metadata": {},
   "source": [
    "## Kernel source and launch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3608616-95bf-453f-8bd4-f35ed1bc39f5",
   "metadata": {},
   "source": [
    "## Resource cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3615d12d-72cc-472e-8660-49654962c510",
   "metadata": {},
   "source": [
    "## Object oriented types for memory safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf05b02d-96f6-40f1-9840-1e586c1b6e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
